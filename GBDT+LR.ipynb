{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly as plot\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import cufflinks as cf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "import plotly.offline as pyo\n",
    "from plotly.offline import init_notebook_mode,plot,iplot\n",
    "dataset=pd.read_csv('cleve.csv')\n",
    "\n",
    "X=dataset.iloc[:,:-1].values\n",
    "y=dataset.iloc[:,13].values\n",
    "dataset.head()\n",
    "#imputation for data cleaning i.e; replace missing values with mean values\n",
    "from sklearn.impute import SimpleImputer\n",
    "Imputation=SimpleImputer(strategy=\"mean\",missing_values=np.nan, fill_value=None, verbose=0, copy=True, add_indicator=False)\n",
    "X[:,11:13]=Imputation.fit_transform(X[:,11:13])\n",
    "\n",
    "#divide dataset into train and test set\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=63)\n",
    "#Scaling is a technique of feature Scaling process\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler(with_mean=True,with_std=True)\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC of GBT+LR is: 0.8939393939393939\n",
      "77.04918032786885\n"
     ]
    }
   ],
   "source": [
    "##GBDT+LR\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X_train, X_train_lr, y_train, y_train_lr = train_test_split(X_train, y_train, test_size=0.2,random_state=45)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "grd = GradientBoostingClassifier(n_estimators=10)\n",
    "grd_enc = OneHotEncoder()\n",
    "grd_lm = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "grd.fit(X_train, y_train)\n",
    "grd_enc.fit(grd.apply(X_train)[:, :, 0])\n",
    "grd_lm.fit(grd_enc.transform(grd.apply(X_train_lr)[:, :, 0]), y_train_lr)\n",
    " \n",
    "y_pred_grd_lm = grd_lm.predict_proba(\n",
    "grd_enc.transform(grd.apply(X_test)[:, :, 0]))[:, 1]\n",
    "#fpr_grd_lm, tpr_grd_lm, _ = roc_curve(y_test, y_pred_grd_lm)\n",
    "print(\"The AUC of GBT+LR is:\", roc_auc_score(y_test, y_pred_grd_lm))\n",
    "\n",
    "l=[round(i) for i in y_pred_grd_lm]\n",
    "print(accuracy_score(y_test,l)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
